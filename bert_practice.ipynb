{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_practice.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj_7Tz0-pK69"
      },
      "source": [
        "!pip install -q -U watermark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjsbi1u3QFEM"
      },
      "source": [
        "!pip install -qq transformers==2.8.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJqoaFpVpoM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f204d0c-61e1-4d70-a088-c984f4bfbfa4"
      },
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.7.10\n",
            "IPython version      : 5.5.0\n",
            "\n",
            "numpy       : 1.19.5\n",
            "pandas      : 1.1.5\n",
            "torch       : 1.8.1+cu101\n",
            "transformers: 2.8.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufzPdoTtNikq"
      },
      "source": [
        "## Data Exploration\n",
        "\n",
        "Download the Google Play app reviews dataset using the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgPRhuMzi9ot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b66fea18-828c-4240-8be0-6cc5b94c2730"
      },
      "source": [
        "!gdown --id 1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
        "!gdown --id 1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
            "To: /content/apps.csv\n",
            "100% 134k/134k [00:00<00:00, 39.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv\n",
            "To: /content/reviews.csv\n",
            "7.17MB [00:00, 113MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7GO8vXo6IVO"
      },
      "source": [
        "Here is how it looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUKLyKc7I6Qp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "3e00617c-da4e-4c3b-9560-78c12147a109"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"reviews.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userName</th>\n",
              "      <th>userImage</th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "      <th>reviewCreatedVersion</th>\n",
              "      <th>at</th>\n",
              "      <th>replyContent</th>\n",
              "      <th>repliedAt</th>\n",
              "      <th>sortOrder</th>\n",
              "      <th>appId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Andrew Thomas</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiHd...</td>\n",
              "      <td>Update: After getting a response from the deve...</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-05 22:25:57</td>\n",
              "      <td>According to our TOS, and the term you have ag...</td>\n",
              "      <td>2020-04-05 15:10:24</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Craig Haines</td>\n",
              "      <td>https://lh3.googleusercontent.com/-hoe0kwSJgPQ...</td>\n",
              "      <td>Used it for a fair amount of time without any ...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-04 13:40:01</td>\n",
              "      <td>It sounds like you logged in with a different ...</td>\n",
              "      <td>2020-04-05 15:11:35</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>steven adkins</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiXw...</td>\n",
              "      <td>Your app sucks now!!!!! Used to be good but no...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-01 16:18:13</td>\n",
              "      <td>This sounds odd! We are not aware of any issue...</td>\n",
              "      <td>2020-04-02 16:05:56</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lars Panzerbjørn</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14Gg-h...</td>\n",
              "      <td>It seems OK, but very basic. Recurring tasks n...</td>\n",
              "      <td>1</td>\n",
              "      <td>192</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-12 08:17:34</td>\n",
              "      <td>We do offer this option as part of the Advance...</td>\n",
              "      <td>2020-03-15 06:20:13</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Scott Prewitt</td>\n",
              "      <td>https://lh3.googleusercontent.com/-K-X1-YsVd6U...</td>\n",
              "      <td>Absolutely worthless. This app runs a prohibit...</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-14 17:41:01</td>\n",
              "      <td>We're sorry you feel this way! 90% of the app ...</td>\n",
              "      <td>2020-03-15 23:45:51</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           userName  ...      appId\n",
              "0     Andrew Thomas  ...  com.anydo\n",
              "1      Craig Haines  ...  com.anydo\n",
              "2     steven adkins  ...  com.anydo\n",
              "3  Lars Panzerbjørn  ...  com.anydo\n",
              "4     Scott Prewitt  ...  com.anydo\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei0xmdi1Chp0"
      },
      "source": [
        "def to_sentiment(rating):\n",
        "  rating = int(rating)\n",
        "  if rating <= 2:\n",
        "    return 0\n",
        "  elif rating == 3:\n",
        "    return 1\n",
        "  else: \n",
        "    return 2\n",
        "\n",
        "df['sentiment'] = df.score.apply(to_sentiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-155O-SFSqE"
      },
      "source": [
        "class_names = ['negative', 'neutral', 'positive']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aHyGuTFgyPO"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "Let's now load a pre-trained BERT model and the corresponding tokenizer, which converts text data into tokens. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7Mj-0ne--5t"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3AfJSZ8NNLF"
      },
      "source": [
        "import transformers\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfrSbwTQ-wi_"
      },
      "source": [
        "Let's see how tokenization works. Here is the test sentence. Convert into tokens using the `tokenizer.tokenize` and `tokenizer.convert_tokens_to_ids` methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZMitwrqm2eb"
      },
      "source": [
        "sample_txt = 'Every day feels like the same during the lock down.'\n",
        "\n",
        "tokens = tokenizer.tokenize(sample_txt)\n",
        "token_id = tokenizer.convert_tokens_to_ids(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTFhpHpsoWO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a92a7677-224f-43d8-e6cd-add2ec12dd4d"
      },
      "source": [
        "\n",
        "print('Tokens are:')\n",
        "print(tokens)\n",
        "print('Token IDs are:')\n",
        "print(token_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokens are:\n",
            "['Every', 'day', 'feels', 'like', 'the', 'same', 'during', 'the', 'lock', 'down', '.']\n",
            "Token IDs are:\n",
            "[4081, 1285, 5115, 1176, 1103, 1269, 1219, 1103, 5842, 1205, 119]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9ap7jdL0LYU"
      },
      "source": [
        "BERT has special tokens for sentence separators \\[SEP\\] and unknown words \\[UNK\\]. This can be done using the [`encode_plus()`](https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizer.encode_plus) method, which takes the test sentence and encodes it into `input_ids`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vea9edaaxSPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e99cc52-a798-49da-e8c5-b8c57e2d937e"
      },
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  sample_txt,\n",
        "  max_length=32,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS69c8WvdOED"
      },
      "source": [
        "The token ids are now stored in a Tensor and padded to a length of 32:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzBmcOla0yQR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18582893-dbe1-41f3-fbcc-56dd7efdc083"
      },
      "source": [
        "print(len(encoding['input_ids'][0]))\n",
        "encoding['input_ids'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 101, 4081, 1285, 5115, 1176, 1103, 1269, 1219, 1103, 5842, 1205,  119,\n",
              "         102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itAyVPsNdyc1"
      },
      "source": [
        "The attention mask has the same length:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wiv5LLiw03Ox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "967f87b1-adde-47b7-a972-929bf4781790"
      },
      "source": [
        "print(len(encoding['attention_mask'][0]))\n",
        "encoding['attention_mask']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1RvhC4jNHHy"
      },
      "source": [
        "Use the `tokenizer.convert_ids_to_tokens` method to invert the encoded token ids (the above tensor of length 32) and visualize the sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IagGoafKLUwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ee9b47c-5fba-4f82-f414-cd765e1f80fb"
      },
      "source": [
        "tokens_inv = tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])\n",
        "sentence = ''\n",
        "for i in tokens_inv:\n",
        "  if not i.startswith('['):\n",
        "    if i != '.':\n",
        "      sentence += ' '\n",
        "    sentence += i\n",
        "print(sentence)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Every day feels like the same during the lock down.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW6ajl30t6du"
      },
      "source": [
        "Most reviews in the dataset contain less than around 120 tokens, but let us choose a maximum length of 160."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7xSmJtLuoxW"
      },
      "source": [
        "MAX_LEN = 160"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvvcoU6nurHy"
      },
      "source": [
        "# Building the dataset\n",
        "\n",
        "Let's now create a dataset using the tokenizer. Here is some code that does this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2BPgRJ7YBK0"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2uwsvCYqDJK"
      },
      "source": [
        "The tokenizer is doing most of the heavy lifting for us. We also return the review texts, so it'll be easier to evaluate the predictions from our model. Let's split the data into 90-5-5 train-validation-test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-vWzoo81dvO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac0a1eb4-4c8c-4474-84d0-4cac5925d48f"
      },
      "source": [
        "df_train = df.sample(frac=0.9, random_state=1)\n",
        "df = df.drop(df_train.index)\n",
        "df_test = df.sample(frac=0.5, random_state=1)\n",
        "df = df.drop(df_test.index)\n",
        "df_val = df\n",
        "\n",
        "print('Size of training dataset is:   ', len(df_train))\n",
        "print('Size of testing dataset is:    ', len(df_test))\n",
        "print('Size of validation dataset is: ', len(df_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of training dataset is:    14171\n",
            "Size of testing dataset is:     788\n",
            "Size of validation dataset is:  787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4tQ1x-vqNab"
      },
      "source": [
        "We also need to create a couple of data loaders:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEGqcvkuOuTX"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df['content'].to_numpy(),\n",
        "    targets=df['sentiment'].to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vODDxMKsPHqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72cbff87-34de-41e8-b038-78e34236d3fc"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6dlOptwqlhF"
      },
      "source": [
        "Let's have a look at an example batch from our training data loader:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y93ldSN47FeT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34d825b8-5da8-432c-ebe0-915adfeff11f"
      },
      "source": [
        "import torch\n",
        "\n",
        "data = next(iter(train_data_loader))\n",
        "data.keys()\n",
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 160])\n",
            "torch.Size([16, 160])\n",
            "torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "440Nd31VTHER"
      },
      "source": [
        "Let's now load the basic [BertModel](https://huggingface.co/transformers/model_doc/bert.html#bertmodel) and build our sentiment classifier on top of it. Load the model using:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P41FayISNRI"
      },
      "source": [
        "from transformers import BertModel, BertConfig\n",
        "\n",
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFE7YSbFdY4t"
      },
      "source": [
        "And encode our sample text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1aoFxbQSn15"
      },
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'], \n",
        "  attention_mask=encoding['attention_mask'],\n",
        "  # return_dict = False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLLu8zmqbaHV"
      },
      "source": [
        "The `last_hidden_state` is the sequence of hidden states of the last layer of the model. The `pooled_output` can be thought of as a summary of the content in the test sentence. Try printing out the sizes of `last_hidden_state` and `pooled_output`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUJHXNpIbcci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feaaf9ed-14e7-4724-a1f9-7dc5c21cfd2c"
      },
      "source": [
        "print('Size of the hidden states:   ', last_hidden_state.shape)\n",
        "print('Size of the pooled output:   ', pooled_output.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of the hidden states:    torch.Size([1, 32, 768])\n",
            "Size of the pooled output:    torch.Size([1, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o_NiS3WgOFf"
      },
      "source": [
        "We can use all of this knowledge to create a classifier that uses the BERT model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_mRflxPl32F"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJg8m3NQJahc"
      },
      "source": [
        "Note that our sentiment classifier takes the BERT backbone and adds a dropout layer (for regularization) and a linear dense layer, which we train using cross-entropy. Let's create an instance and move it to the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0yQnuSFsjDp"
      },
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "model = SentimentClassifier(len(class_names))\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCPCFDLlKIQd"
      },
      "source": [
        "We'll move the example batch of our training data to the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz7p__CqdaMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8b2f805-f8e3-4471-9222-4ca42dbbe86c"
      },
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  101, 22597,  5616,  ...,     0,     0,     0],\n",
            "        [  101,  4209,  2495,  ...,     0,     0,     0],\n",
            "        [  101,   146,  1274,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 11568,  2716,  ...,     0,     0,     0],\n",
            "        [  101,   138,  1363,  ...,     0,     0,     0],\n",
            "        [  101,  2750,   119,  ...,     0,     0,     0]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr1EgkEtKOIB"
      },
      "source": [
        "To get the predicted probabilities from our trained model, we'll apply the softmax function to the outputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC6PQTgdGOAr"
      },
      "source": [
        "!pip install -qq transformers==2.8.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rTCj46Zamry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46ef4089-bc2e-4184-8c5a-128259f42950"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "F.softmax(model(input_ids, attention_mask), dim=1)\n",
        "\n",
        "# output = model(input_ids, attention_mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5630, 0.1511, 0.2859],\n",
              "        [0.5061, 0.1868, 0.3071],\n",
              "        [0.6414, 0.1582, 0.2004],\n",
              "        [0.4051, 0.2413, 0.3537],\n",
              "        [0.5771, 0.0869, 0.3360],\n",
              "        [0.5919, 0.1640, 0.2441],\n",
              "        [0.5073, 0.1576, 0.3351],\n",
              "        [0.5633, 0.1303, 0.3064],\n",
              "        [0.5266, 0.1587, 0.3147],\n",
              "        [0.6047, 0.1272, 0.2681],\n",
              "        [0.5286, 0.1747, 0.2967],\n",
              "        [0.4862, 0.1227, 0.3911],\n",
              "        [0.5340, 0.1519, 0.3140],\n",
              "        [0.3914, 0.1263, 0.4824],\n",
              "        [0.7726, 0.0779, 0.1495],\n",
              "        [0.4213, 0.3026, 0.2761]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9xikRdtRN1N"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76g7FV85H-T8"
      },
      "source": [
        "To train the model, we will use the AdamW optimizer and a linear learning-rate scheduler with no warmup steps, along with the cross-entropy loss. Five epochs (full passes through the training data should be enough) should be enough, but you can experiment with more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v-ArJ2fCCcU"
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8522g7JIu5J"
      },
      "source": [
        "\n",
        "Let's continue with writing a helper function for training our model for one epoch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzl9UhuNx1_Q"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def train_epoch(\n",
        "  model, \n",
        "  data_loader, \n",
        "  loss_fn, \n",
        "  optimizer, \n",
        "  device, \n",
        "  scheduler, \n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    input_ids = d['input_ids'].to(device)\n",
        "    attention_mask = d['attention_mask'].to(device)\n",
        "    targets = d['targets'].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds==targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4PniYIte0fr"
      },
      "source": [
        "Let's write another function that helps us evaluate the model on a given data loader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXeRorVGIKre"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    \n",
        "    input_ids = d['input_ids'].to(device)\n",
        "    attention_mask = d['attention_mask'].to(device)\n",
        "    targets = d['targets'].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds==targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_rdSDBHhhCh"
      },
      "source": [
        "Using those two, we can write our training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zhHoFNsxufs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e81bcf10-22aa-47d4-8837-973861ecbfa1"
      },
      "source": [
        "%%time\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(model=model,\n",
        "                                      data_loader=train_data_loader,\n",
        "                                      loss_fn=loss_fn,\n",
        "                                      optimizer=optimizer,\n",
        "                                      device=device,\n",
        "                                      scheduler=scheduler,\n",
        "                                      n_examples=len(df_train))\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(model=model,\n",
        "                                      data_loader=val_data_loader,\n",
        "                                      loss_fn=loss_fn,\n",
        "                                      device=device,\n",
        "                                      n_examples=len(df_val))\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.41343874894460964 accuracy 0.8417190035988992\n",
            "Val   loss 0.506066627157852 accuracy 0.843710292249047\n",
            "\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.2203027001076481 accuracy 0.9292216498482817\n",
            "Val   loss 0.5708163423929363 accuracy 0.8678526048284626\n",
            "\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.14176541054923544 accuracy 0.9580834097805377\n",
            "Val   loss 0.5859570736205205 accuracy 0.8716645489199493\n",
            "\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.10539008374260234 accuracy 0.9693740738127161\n",
            "Val   loss 0.5805639847018756 accuracy 0.8805590851334181\n",
            "\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.088685419645203 accuracy 0.9727612730223697\n",
            "Val   loss 0.5805639847018756 accuracy 0.8805590851334181\n",
            "\n",
            "CPU times: user 37min 1s, sys: 26min 47s, total: 1h 3min 49s\n",
            "Wall time: 1h 3min 56s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r8-5zWsiVur"
      },
      "source": [
        "Note that we're storing the best model, indicated by the highest validation accuracy.\n",
        "\n",
        "Plot train and validation accuracy as a function of epoch count."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FWG7kBm372V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "2688001f-2680-425a-9130-bcd14a0505dc"
      },
      "source": [
        "plt.plot(np.arange(1, EPOCHS+1), history['train_acc'], label='Training Accuracies')\n",
        "plt.plot(np.arange(1, EPOCHS+1), history['val_acc'], label='Validation Accuracies')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracies')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4a195624d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsHqkLAuf8pv"
      },
      "source": [
        "You might try to fine-tune the parameters (learning rate, batch size) a bit more if accuracy is not good enough.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3HZb3NWFtFf"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "So how good is our model on predicting sentiment?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdQ7-ylCj8Gd"
      },
      "source": [
        "We'll define a helper function to get the predictions from our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgR6MuNS8jr_"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  \n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkbnBTI7kd_y"
      },
      "source": [
        "This is similar to the evaluation function, except that we're storing the text of the reviews and the predicted probabilities (by applying the softmax on the model outputs):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHdPZr60-0c_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3949d168-74c6-4c2f-c54a-cb63e66519f8"
      },
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFAekw3mmWUi"
      },
      "source": [
        "Let us compare true sentiment vs predicted sentiment by plotting a confusion matrix of `y_test` vs `y_pred`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d1qxsc__DTh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "0dbe0571-cf5a-4d89-822e-8f1d423e3218"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(y_true=y_test, y_pred = y_pred)\n",
        "disp = ConfusionMatrixDisplay(cm, ['True', 'Predicted'])\n",
        "disp.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f4a18c23c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WL5pDmvFyaU"
      },
      "source": [
        "### Predicting on Raw Text\n",
        "\n",
        "Let's use our model to predict the sentiment of some raw text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEPi7zQRsDhH"
      },
      "source": [
        "review_text = \"I love Deep Learning! Best course evah!!!1!!\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et8xlDrKpH60"
      },
      "source": [
        "Use your trained model to predict the sentiment expressed in `review_text`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr_t3rUksumr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c0dfe66-a271-4a1b-b0a5-c1578610d75f"
      },
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  review_text,\n",
        "  max_length=160,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "input_ids = encoding[\"input_ids\"].to(device)\n",
        "attention_mask = encoding[\"attention_mask\"].to(device)\n",
        "\n",
        "outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "_, pred = torch.max(outputs, dim=1)\n",
        "\n",
        "print(pred[0])\n",
        "print('Indicating that review_text has a POSITIVE sentiment.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2, device='cuda:0')\n",
            "Indicating that review_text has a POSITIVE sentiment.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf39tauBa2V2"
      },
      "source": [
        "## References\n",
        "\n",
        "- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\n",
        "- [L11 Language Models - Alec Radford (OpenAI)](https://www.youtube.com/watch?v=BnpB3GrpsfM)\n",
        "- [The Illustrated BERT, ELMo, and co.](https://jalammar.github.io/illustrated-bert/)\n",
        "- [BERT Fine-Tuning Tutorial with PyTorch](https://mccormickml.com/2019/07/22/BERT-fine-tuning/)\n",
        "- [How to Fine-Tune BERT for Text Classification?](https://arxiv.org/pdf/1905.05583.pdf)\n",
        "- [Huggingface Transformers](https://huggingface.co/transformers/)\n",
        "- [BERT Explained: State of the art language model for NLP](https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270)"
      ]
    }
  ]
}